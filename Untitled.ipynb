{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=1000, n_features=8, n_informative=5, n_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03162588,  0.82000498,  0.79664423, -3.87655333,  2.02863298,\n",
       "        2.17132864,  1.83577588,  4.40589002])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, 0, 1, 3, 1, 0, 0, 2, 0, 3, 1, 3, 3, 1, 3, 2, 1, 0, 0, 0,\n",
       "       2, 2, 0, 2, 2, 0, 1, 2, 3, 2, 0, 3, 1, 0, 0, 1, 2, 0, 0, 3, 3, 3,\n",
       "       3, 1, 0, 0, 0, 1, 0, 3, 2, 3, 0, 0, 2, 0, 3, 3, 2, 0, 3, 2, 0, 0,\n",
       "       1, 1, 2, 3, 1, 3, 1, 0, 2, 1, 2, 0, 2, 3, 1, 0, 0, 2, 0, 1, 3, 1,\n",
       "       0, 0, 2, 0, 2, 3, 2, 2, 2, 0, 0, 2, 2, 0, 3, 2, 3, 3, 0, 1, 3, 1,\n",
       "       2, 2, 2, 1, 2, 1, 3, 1, 3, 0, 3, 3, 2, 3, 3, 0, 0, 3, 1, 0, 3, 1,\n",
       "       3, 0, 1, 3, 1, 1, 2, 2, 1, 3, 1, 2, 3, 1, 0, 2, 2, 1, 0, 1, 0, 3,\n",
       "       2, 0, 0, 3, 0, 0, 0, 3, 0, 0, 1, 1, 3, 1, 1, 3, 2, 3, 3, 1, 2, 1,\n",
       "       2, 3, 2, 2, 2, 2, 0, 0, 0, 1, 3, 2, 2, 3, 2, 0, 2, 1, 2, 3, 1, 2,\n",
       "       3, 3, 1, 2, 3, 1, 2, 0, 0, 1, 1, 3, 2, 0, 2, 1, 3, 3, 1, 1, 0, 2,\n",
       "       2, 0, 1, 3, 3, 3, 0, 1, 1, 2, 1, 3, 0, 2, 1, 2, 1, 3, 1, 3, 1, 3,\n",
       "       2, 3, 3, 0, 2, 2, 2, 3, 0, 0, 0, 1, 3, 1, 1, 2, 1, 0, 1, 0, 0, 2,\n",
       "       1, 1, 1, 2, 2, 0, 2, 1, 2, 2, 2, 0, 0, 3, 2, 0, 0, 3, 0, 0, 0, 1,\n",
       "       3, 1, 2, 1, 3, 0, 3, 2, 2, 1, 0, 3, 0, 3, 1, 3, 0, 1, 3, 0, 1, 1,\n",
       "       2, 1, 0, 1, 3, 1, 3, 0, 1, 3, 3, 3, 0, 1, 1, 2, 0, 0, 1, 3, 0, 0,\n",
       "       2, 1, 1, 1, 1, 2, 1, 2, 2, 3, 1, 2, 3, 0, 2, 1, 2, 0, 0, 0, 2, 0,\n",
       "       3, 2, 1, 1, 1, 1, 0, 2, 2, 3, 1, 0, 1, 1, 0, 2, 1, 3, 1, 1, 0, 0,\n",
       "       1, 2, 2, 2, 2, 0, 0, 3, 2, 0, 0, 1, 1, 0, 2, 0, 3, 0, 3, 3, 3, 2,\n",
       "       3, 2, 3, 2, 3, 3, 2, 0, 3, 0, 1, 2, 3, 3, 2, 3, 1, 0, 0, 3, 0, 0,\n",
       "       3, 2, 1, 2, 2, 1, 3, 0, 1, 2, 3, 2, 3, 3, 1, 2, 3, 2, 1, 2, 1, 1,\n",
       "       2, 0, 0, 0, 0, 2, 3, 3, 2, 0, 2, 0, 2, 3, 3, 1, 3, 1, 3, 2, 1, 3,\n",
       "       0, 3, 1, 1, 1, 0, 1, 2, 3, 2, 3, 3, 3, 3, 3, 2, 0, 0, 3, 3, 2, 2,\n",
       "       0, 0, 3, 3, 1, 3, 2, 2, 1, 3, 0, 1, 0, 2, 1, 1, 0, 2, 3, 2, 1, 2,\n",
       "       2, 0, 0, 3, 0, 0, 0, 3, 0, 1, 0, 3, 2, 3, 2, 2, 3, 0, 1, 3, 0, 3,\n",
       "       0, 0, 3, 1, 0, 1, 1, 0, 1, 3, 1, 1, 3, 1, 0, 0, 1, 2, 3, 3, 2, 3,\n",
       "       2, 0, 3, 0, 2, 0, 3, 1, 2, 2, 2, 3, 0, 1, 3, 3, 2, 2, 0, 2, 0, 2,\n",
       "       3, 2, 3, 0, 1, 1, 2, 0, 1, 2, 0, 0, 0, 3, 2, 0, 2, 1, 0, 1, 1, 2,\n",
       "       0, 2, 2, 0, 2, 0, 2, 2, 1, 2, 0, 2, 3, 0, 3, 0, 1, 3, 0, 3, 3, 2,\n",
       "       1, 0, 2, 1, 3, 2, 3, 0, 0, 0, 2, 3, 2, 2, 0, 0, 2, 2, 1, 3, 0, 3,\n",
       "       1, 3, 2, 1, 1, 2, 2, 1, 0, 2, 3, 3, 2, 0, 2, 3, 2, 0, 2, 0, 1, 3,\n",
       "       2, 3, 1, 2, 3, 3, 3, 3, 3, 1, 1, 0, 1, 1, 1, 2, 2, 1, 3, 3, 3, 0,\n",
       "       2, 1, 3, 1, 0, 3, 0, 1, 0, 1, 2, 2, 2, 3, 0, 3, 3, 0, 0, 0, 2, 0,\n",
       "       0, 3, 2, 1, 1, 1, 3, 0, 3, 0, 2, 3, 2, 2, 3, 0, 0, 1, 3, 0, 1, 3,\n",
       "       0, 0, 1, 3, 3, 0, 1, 3, 3, 2, 0, 1, 1, 2, 1, 3, 3, 3, 1, 1, 3, 3,\n",
       "       1, 1, 2, 3, 1, 1, 1, 2, 3, 3, 2, 1, 2, 1, 0, 2, 2, 0, 1, 1, 0, 2,\n",
       "       3, 0, 3, 1, 0, 2, 1, 1, 2, 1, 2, 3, 1, 1, 0, 1, 1, 1, 3, 0, 3, 0,\n",
       "       0, 0, 1, 3, 2, 1, 3, 1, 1, 3, 0, 2, 1, 3, 3, 2, 3, 0, 0, 2, 0, 0,\n",
       "       1, 1, 3, 3, 3, 2, 3, 0, 2, 3, 1, 2, 1, 2, 0, 0, 1, 1, 0, 3, 1, 3,\n",
       "       3, 1, 0, 2, 2, 1, 2, 1, 2, 1, 3, 2, 2, 0, 3, 2, 2, 2, 3, 3, 1, 3,\n",
       "       1, 1, 3, 2, 1, 2, 2, 3, 2, 1, 0, 1, 0, 1, 2, 3, 3, 0, 0, 2, 0, 0,\n",
       "       0, 1, 0, 1, 0, 2, 1, 0, 3, 2, 2, 2, 0, 1, 1, 1, 2, 1, 1, 0, 2, 1,\n",
       "       1, 3, 0, 1, 2, 0, 2, 0, 0, 3, 0, 3, 3, 2, 0, 2, 3, 2, 0, 3, 1, 3,\n",
       "       3, 2, 2, 0, 1, 2, 3, 2, 1, 3, 1, 3, 3, 0, 3, 1, 1, 3, 0, 1, 3, 2,\n",
       "       0, 1, 2, 0, 2, 2, 3, 0, 2, 0, 1, 3, 3, 0, 0, 2, 2, 1, 3, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 2, 2, 3, 2, 1, 2, 3, 2, 1, 1, 1, 2, 0, 0, 3, 2, 0,\n",
       "       3, 2, 1, 1, 2, 1, 1, 3, 0, 3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(X, columns=['f{}'.format(i) for i in range(8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.031626</td>\n",
       "      <td>0.820005</td>\n",
       "      <td>0.796644</td>\n",
       "      <td>-3.876553</td>\n",
       "      <td>2.028633</td>\n",
       "      <td>2.171329</td>\n",
       "      <td>1.835776</td>\n",
       "      <td>4.405890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.103826</td>\n",
       "      <td>1.389598</td>\n",
       "      <td>-1.205009</td>\n",
       "      <td>-0.335108</td>\n",
       "      <td>1.500547</td>\n",
       "      <td>-1.129068</td>\n",
       "      <td>1.102455</td>\n",
       "      <td>1.930105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.100330</td>\n",
       "      <td>2.090978</td>\n",
       "      <td>1.480690</td>\n",
       "      <td>-0.826699</td>\n",
       "      <td>-1.523320</td>\n",
       "      <td>-3.085676</td>\n",
       "      <td>1.595544</td>\n",
       "      <td>-0.248903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.309997</td>\n",
       "      <td>1.530448</td>\n",
       "      <td>0.624462</td>\n",
       "      <td>2.094778</td>\n",
       "      <td>1.555747</td>\n",
       "      <td>0.517077</td>\n",
       "      <td>-3.136489</td>\n",
       "      <td>-1.228687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.128800</td>\n",
       "      <td>0.534773</td>\n",
       "      <td>-1.692441</td>\n",
       "      <td>1.121159</td>\n",
       "      <td>3.210305</td>\n",
       "      <td>-0.735458</td>\n",
       "      <td>1.873414</td>\n",
       "      <td>4.292030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f0        f1        f2        f3        f4        f5        f6  \\\n",
       "0  0.031626  0.820005  0.796644 -3.876553  2.028633  2.171329  1.835776   \n",
       "1 -1.103826  1.389598 -1.205009 -0.335108  1.500547 -1.129068  1.102455   \n",
       "2 -2.100330  2.090978  1.480690 -0.826699 -1.523320 -3.085676  1.595544   \n",
       "3 -0.309997  1.530448  0.624462  2.094778  1.555747  0.517077 -3.136489   \n",
       "4  1.128800  0.534773 -1.692441  1.121159  3.210305 -0.735458  1.873414   \n",
       "\n",
       "         f7  \n",
       "0  4.405890  \n",
       "1  1.930105  \n",
       "2 -0.248903  \n",
       "3 -1.228687  \n",
       "4  4.292030  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.25, random_state=90210)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters_per_class=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>-0.818248</td>\n",
       "      <td>0.905815</td>\n",
       "      <td>2.163658</td>\n",
       "      <td>-1.630440</td>\n",
       "      <td>0.672566</td>\n",
       "      <td>1.068684</td>\n",
       "      <td>-0.382503</td>\n",
       "      <td>0.647721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.597961</td>\n",
       "      <td>1.234908</td>\n",
       "      <td>-1.367938</td>\n",
       "      <td>-0.281410</td>\n",
       "      <td>-0.992190</td>\n",
       "      <td>-0.963151</td>\n",
       "      <td>0.765393</td>\n",
       "      <td>0.632772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>-3.231091</td>\n",
       "      <td>0.936451</td>\n",
       "      <td>0.438671</td>\n",
       "      <td>0.183244</td>\n",
       "      <td>-0.961653</td>\n",
       "      <td>-3.133924</td>\n",
       "      <td>0.773449</td>\n",
       "      <td>-1.760837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>-0.418698</td>\n",
       "      <td>1.112875</td>\n",
       "      <td>-0.739577</td>\n",
       "      <td>-1.884648</td>\n",
       "      <td>1.970287</td>\n",
       "      <td>-0.132499</td>\n",
       "      <td>2.271196</td>\n",
       "      <td>3.883662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>-0.079530</td>\n",
       "      <td>-1.224110</td>\n",
       "      <td>2.364349</td>\n",
       "      <td>1.501065</td>\n",
       "      <td>2.583743</td>\n",
       "      <td>0.841318</td>\n",
       "      <td>-0.739978</td>\n",
       "      <td>0.543120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>-2.671982</td>\n",
       "      <td>-0.170391</td>\n",
       "      <td>-1.826342</td>\n",
       "      <td>3.452674</td>\n",
       "      <td>-2.891013</td>\n",
       "      <td>-5.151515</td>\n",
       "      <td>-0.026115</td>\n",
       "      <td>-4.950604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>-0.881752</td>\n",
       "      <td>-0.268687</td>\n",
       "      <td>0.365745</td>\n",
       "      <td>-1.238740</td>\n",
       "      <td>1.455195</td>\n",
       "      <td>-0.325197</td>\n",
       "      <td>2.038009</td>\n",
       "      <td>2.345333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>-0.786768</td>\n",
       "      <td>0.827101</td>\n",
       "      <td>-0.290674</td>\n",
       "      <td>4.078403</td>\n",
       "      <td>2.814103</td>\n",
       "      <td>-2.524885</td>\n",
       "      <td>-0.520591</td>\n",
       "      <td>0.412036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>-1.839005</td>\n",
       "      <td>1.062290</td>\n",
       "      <td>-1.235505</td>\n",
       "      <td>0.772864</td>\n",
       "      <td>0.514311</td>\n",
       "      <td>-1.845558</td>\n",
       "      <td>0.067776</td>\n",
       "      <td>-0.445533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.618525</td>\n",
       "      <td>2.800436</td>\n",
       "      <td>1.990405</td>\n",
       "      <td>-3.185111</td>\n",
       "      <td>2.372351</td>\n",
       "      <td>0.963022</td>\n",
       "      <td>2.162247</td>\n",
       "      <td>5.740970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           f0        f1        f2        f3        f4        f5        f6  \\\n",
       "846 -0.818248  0.905815  2.163658 -1.630440  0.672566  1.068684 -0.382503   \n",
       "171  0.597961  1.234908 -1.367938 -0.281410 -0.992190 -0.963151  0.765393   \n",
       "676 -3.231091  0.936451  0.438671  0.183244 -0.961653 -3.133924  0.773449   \n",
       "87  -0.418698  1.112875 -0.739577 -1.884648  1.970287 -0.132499  2.271196   \n",
       "985 -0.079530 -1.224110  2.364349  1.501065  2.583743  0.841318 -0.739978   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "213 -2.671982 -0.170391 -1.826342  3.452674 -2.891013 -5.151515 -0.026115   \n",
       "550 -0.881752 -0.268687  0.365745 -1.238740  1.455195 -0.325197  2.038009   \n",
       "955 -0.786768  0.827101 -0.290674  4.078403  2.814103 -2.524885 -0.520591   \n",
       "965 -1.839005  1.062290 -1.235505  0.772864  0.514311 -1.845558  0.067776   \n",
       "395  0.618525  2.800436  1.990405 -3.185111  2.372351  0.963022  2.162247   \n",
       "\n",
       "           f7  \n",
       "846  0.647721  \n",
       "171  0.632772  \n",
       "676 -1.760837  \n",
       "87   3.883662  \n",
       "985  0.543120  \n",
       "..        ...  \n",
       "213 -4.950604  \n",
       "550  2.345333  \n",
       "955  0.412036  \n",
       "965 -0.445533  \n",
       "395  5.740970  \n",
       "\n",
       "[750 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syeda\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:973: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from typing import Tuple\n",
    "def get_clusters(X_train: pd.DataFrame, X_test: pd.DataFrame, n_clusters: int) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    applies k-means clustering to training data to find clusters and predicts them for the test set\n",
    "    \"\"\"\n",
    "    clustering = KMeans(n_clusters=n_clusters, random_state=8675309,n_jobs=-1)\n",
    "    clustering.fit(X_train)\n",
    "    # apply the labels\n",
    "    train_labels = clustering.labels_\n",
    "    X_train_clstrs = X_train.copy()\n",
    "    X_train_clstrs['clusters'] = train_labels\n",
    "    \n",
    "    # predict labels on the test set\n",
    "    test_labels = clustering.predict(X_test)\n",
    "    X_test_clstrs = X_test.copy()\n",
    "    X_test_clstrs['clusters'] = test_labels\n",
    "    return X_train_clstrs, X_test_clstrs\n",
    "X_train_clstrs, X_test_clstrs = get_clusters(X_train, X_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>-0.818248</td>\n",
       "      <td>0.905815</td>\n",
       "      <td>2.163658</td>\n",
       "      <td>-1.630440</td>\n",
       "      <td>0.672566</td>\n",
       "      <td>1.068684</td>\n",
       "      <td>-0.382503</td>\n",
       "      <td>0.647721</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.597961</td>\n",
       "      <td>1.234908</td>\n",
       "      <td>-1.367938</td>\n",
       "      <td>-0.281410</td>\n",
       "      <td>-0.992190</td>\n",
       "      <td>-0.963151</td>\n",
       "      <td>0.765393</td>\n",
       "      <td>0.632772</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>-3.231091</td>\n",
       "      <td>0.936451</td>\n",
       "      <td>0.438671</td>\n",
       "      <td>0.183244</td>\n",
       "      <td>-0.961653</td>\n",
       "      <td>-3.133924</td>\n",
       "      <td>0.773449</td>\n",
       "      <td>-1.760837</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>-0.418698</td>\n",
       "      <td>1.112875</td>\n",
       "      <td>-0.739577</td>\n",
       "      <td>-1.884648</td>\n",
       "      <td>1.970287</td>\n",
       "      <td>-0.132499</td>\n",
       "      <td>2.271196</td>\n",
       "      <td>3.883662</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>-0.079530</td>\n",
       "      <td>-1.224110</td>\n",
       "      <td>2.364349</td>\n",
       "      <td>1.501065</td>\n",
       "      <td>2.583743</td>\n",
       "      <td>0.841318</td>\n",
       "      <td>-0.739978</td>\n",
       "      <td>0.543120</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>-2.671982</td>\n",
       "      <td>-0.170391</td>\n",
       "      <td>-1.826342</td>\n",
       "      <td>3.452674</td>\n",
       "      <td>-2.891013</td>\n",
       "      <td>-5.151515</td>\n",
       "      <td>-0.026115</td>\n",
       "      <td>-4.950604</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>-0.881752</td>\n",
       "      <td>-0.268687</td>\n",
       "      <td>0.365745</td>\n",
       "      <td>-1.238740</td>\n",
       "      <td>1.455195</td>\n",
       "      <td>-0.325197</td>\n",
       "      <td>2.038009</td>\n",
       "      <td>2.345333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>-0.786768</td>\n",
       "      <td>0.827101</td>\n",
       "      <td>-0.290674</td>\n",
       "      <td>4.078403</td>\n",
       "      <td>2.814103</td>\n",
       "      <td>-2.524885</td>\n",
       "      <td>-0.520591</td>\n",
       "      <td>0.412036</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>-1.839005</td>\n",
       "      <td>1.062290</td>\n",
       "      <td>-1.235505</td>\n",
       "      <td>0.772864</td>\n",
       "      <td>0.514311</td>\n",
       "      <td>-1.845558</td>\n",
       "      <td>0.067776</td>\n",
       "      <td>-0.445533</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.618525</td>\n",
       "      <td>2.800436</td>\n",
       "      <td>1.990405</td>\n",
       "      <td>-3.185111</td>\n",
       "      <td>2.372351</td>\n",
       "      <td>0.963022</td>\n",
       "      <td>2.162247</td>\n",
       "      <td>5.740970</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           f0        f1        f2        f3        f4        f5        f6  \\\n",
       "846 -0.818248  0.905815  2.163658 -1.630440  0.672566  1.068684 -0.382503   \n",
       "171  0.597961  1.234908 -1.367938 -0.281410 -0.992190 -0.963151  0.765393   \n",
       "676 -3.231091  0.936451  0.438671  0.183244 -0.961653 -3.133924  0.773449   \n",
       "87  -0.418698  1.112875 -0.739577 -1.884648  1.970287 -0.132499  2.271196   \n",
       "985 -0.079530 -1.224110  2.364349  1.501065  2.583743  0.841318 -0.739978   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "213 -2.671982 -0.170391 -1.826342  3.452674 -2.891013 -5.151515 -0.026115   \n",
       "550 -0.881752 -0.268687  0.365745 -1.238740  1.455195 -0.325197  2.038009   \n",
       "955 -0.786768  0.827101 -0.290674  4.078403  2.814103 -2.524885 -0.520591   \n",
       "965 -1.839005  1.062290 -1.235505  0.772864  0.514311 -1.845558  0.067776   \n",
       "395  0.618525  2.800436  1.990405 -3.185111  2.372351  0.963022  2.162247   \n",
       "\n",
       "           f7  clusters  \n",
       "846  0.647721         1  \n",
       "171  0.632772         0  \n",
       "676 -1.760837         0  \n",
       "87   3.883662         1  \n",
       "985  0.543120         1  \n",
       "..        ...       ...  \n",
       "213 -4.950604         0  \n",
       "550  2.345333         1  \n",
       "955  0.412036         0  \n",
       "965 -0.445533         0  \n",
       "395  5.740970         1  \n",
       "\n",
       "[750 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_clstrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>0.218247</td>\n",
       "      <td>-0.913889</td>\n",
       "      <td>1.214035</td>\n",
       "      <td>0.451748</td>\n",
       "      <td>1.596396</td>\n",
       "      <td>0.954109</td>\n",
       "      <td>-0.262487</td>\n",
       "      <td>0.714396</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>-0.786061</td>\n",
       "      <td>0.685774</td>\n",
       "      <td>-0.044181</td>\n",
       "      <td>-1.200313</td>\n",
       "      <td>1.016108</td>\n",
       "      <td>0.553624</td>\n",
       "      <td>0.158128</td>\n",
       "      <td>1.092400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>1.153480</td>\n",
       "      <td>1.484747</td>\n",
       "      <td>-1.847979</td>\n",
       "      <td>1.852757</td>\n",
       "      <td>1.522084</td>\n",
       "      <td>-1.706536</td>\n",
       "      <td>1.006985</td>\n",
       "      <td>2.500490</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>1.043747</td>\n",
       "      <td>-0.729940</td>\n",
       "      <td>0.378634</td>\n",
       "      <td>0.775970</td>\n",
       "      <td>1.614299</td>\n",
       "      <td>1.354780</td>\n",
       "      <td>-0.675926</td>\n",
       "      <td>0.874227</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>-2.262530</td>\n",
       "      <td>0.895466</td>\n",
       "      <td>-0.469930</td>\n",
       "      <td>-0.104919</td>\n",
       "      <td>-0.998157</td>\n",
       "      <td>-2.298559</td>\n",
       "      <td>0.625288</td>\n",
       "      <td>-1.267778</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>0.598910</td>\n",
       "      <td>1.805000</td>\n",
       "      <td>1.265647</td>\n",
       "      <td>0.606426</td>\n",
       "      <td>-1.493364</td>\n",
       "      <td>-0.557787</td>\n",
       "      <td>-1.269613</td>\n",
       "      <td>-1.239669</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.868436</td>\n",
       "      <td>-1.161077</td>\n",
       "      <td>0.664796</td>\n",
       "      <td>1.469088</td>\n",
       "      <td>0.582728</td>\n",
       "      <td>0.629326</td>\n",
       "      <td>-0.858580</td>\n",
       "      <td>-0.537251</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>-1.618635</td>\n",
       "      <td>0.647651</td>\n",
       "      <td>-0.226243</td>\n",
       "      <td>-2.400048</td>\n",
       "      <td>0.891439</td>\n",
       "      <td>-1.362169</td>\n",
       "      <td>3.338723</td>\n",
       "      <td>3.090665</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>1.564084</td>\n",
       "      <td>0.379752</td>\n",
       "      <td>-0.836431</td>\n",
       "      <td>0.096723</td>\n",
       "      <td>-0.826671</td>\n",
       "      <td>0.522014</td>\n",
       "      <td>-0.384545</td>\n",
       "      <td>0.079808</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1.074932</td>\n",
       "      <td>-0.557422</td>\n",
       "      <td>-1.271525</td>\n",
       "      <td>0.119592</td>\n",
       "      <td>-0.238715</td>\n",
       "      <td>-0.758390</td>\n",
       "      <td>1.763809</td>\n",
       "      <td>1.399511</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           f0        f1        f2        f3        f4        f5        f6  \\\n",
       "214  0.218247 -0.913889  1.214035  0.451748  1.596396  0.954109 -0.262487   \n",
       "459 -0.786061  0.685774 -0.044181 -1.200313  1.016108  0.553624  0.158128   \n",
       "230  1.153480  1.484747 -1.847979  1.852757  1.522084 -1.706536  1.006985   \n",
       "479  1.043747 -0.729940  0.378634  0.775970  1.614299  1.354780 -0.675926   \n",
       "597 -2.262530  0.895466 -0.469930 -0.104919 -0.998157 -2.298559  0.625288   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "698  0.598910  1.805000  1.265647  0.606426 -1.493364 -0.557787 -1.269613   \n",
       "27   0.868436 -1.161077  0.664796  1.469088  0.582728  0.629326 -0.858580   \n",
       "650 -1.618635  0.647651 -0.226243 -2.400048  0.891439 -1.362169  3.338723   \n",
       "432  1.564084  0.379752 -0.836431  0.096723 -0.826671  0.522014 -0.384545   \n",
       "199  1.074932 -0.557422 -1.271525  0.119592 -0.238715 -0.758390  1.763809   \n",
       "\n",
       "           f7  clusters  \n",
       "214  0.714396         1  \n",
       "459  1.092400         1  \n",
       "230  2.500490         1  \n",
       "479  0.874227         1  \n",
       "597 -1.267778         0  \n",
       "..        ...       ...  \n",
       "698 -1.239669         0  \n",
       "27  -0.537251         1  \n",
       "650  3.090665         1  \n",
       "432  0.079808         1  \n",
       "199  1.399511         1  \n",
       "\n",
       "[250 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_clstrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "def scale_features(X_train: pd.DataFrame, X_test: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    applies standard scaler (z-scores) to training data and predicts z-scores for the test set\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    to_scale = [col for col in X_train.columns.values]\n",
    "    scaler.fit(X_train[to_scale])\n",
    "    X_train[to_scale] = scaler.transform(X_train[to_scale])\n",
    "    \n",
    "    # predict z-scores on the test set\n",
    "    X_test[to_scale] = scaler.transform(X_test[to_scale])\n",
    "    \n",
    "    return X_train, X_test\n",
    "X_train_scaled, X_test_scaled = scale_features(X_train_clstrs, X_test_clstrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>-0.506020</td>\n",
       "      <td>0.539483</td>\n",
       "      <td>2.124813</td>\n",
       "      <td>-1.410443</td>\n",
       "      <td>0.281646</td>\n",
       "      <td>0.704983</td>\n",
       "      <td>-0.335682</td>\n",
       "      <td>0.207109</td>\n",
       "      <td>0.958206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.329096</td>\n",
       "      <td>0.767773</td>\n",
       "      <td>-1.346558</td>\n",
       "      <td>-0.523517</td>\n",
       "      <td>-0.736579</td>\n",
       "      <td>-0.215310</td>\n",
       "      <td>0.372510</td>\n",
       "      <td>0.200423</td>\n",
       "      <td>-1.043617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>-1.928833</td>\n",
       "      <td>0.560735</td>\n",
       "      <td>0.429243</td>\n",
       "      <td>-0.218027</td>\n",
       "      <td>-0.717902</td>\n",
       "      <td>-1.198535</td>\n",
       "      <td>0.377480</td>\n",
       "      <td>-0.870036</td>\n",
       "      <td>-1.043617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>-0.270411</td>\n",
       "      <td>0.683119</td>\n",
       "      <td>-0.728913</td>\n",
       "      <td>-1.577573</td>\n",
       "      <td>1.075379</td>\n",
       "      <td>0.160923</td>\n",
       "      <td>1.301512</td>\n",
       "      <td>1.654272</td>\n",
       "      <td>0.958206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>-0.070410</td>\n",
       "      <td>-0.938034</td>\n",
       "      <td>2.322082</td>\n",
       "      <td>0.648380</td>\n",
       "      <td>1.450591</td>\n",
       "      <td>0.602001</td>\n",
       "      <td>-0.556225</td>\n",
       "      <td>0.160330</td>\n",
       "      <td>0.958206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>-1.599135</td>\n",
       "      <td>-0.207075</td>\n",
       "      <td>-1.797146</td>\n",
       "      <td>1.931475</td>\n",
       "      <td>-1.897968</td>\n",
       "      <td>-2.112377</td>\n",
       "      <td>-0.115809</td>\n",
       "      <td>-2.296550</td>\n",
       "      <td>-1.043617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>-0.543467</td>\n",
       "      <td>-0.275262</td>\n",
       "      <td>0.357560</td>\n",
       "      <td>-1.152918</td>\n",
       "      <td>0.760330</td>\n",
       "      <td>0.073643</td>\n",
       "      <td>1.157647</td>\n",
       "      <td>0.966308</td>\n",
       "      <td>0.958206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>-0.487456</td>\n",
       "      <td>0.484879</td>\n",
       "      <td>-0.287665</td>\n",
       "      <td>2.342864</td>\n",
       "      <td>1.591488</td>\n",
       "      <td>-0.922678</td>\n",
       "      <td>-0.420875</td>\n",
       "      <td>0.101707</td>\n",
       "      <td>-1.043617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>-1.107943</td>\n",
       "      <td>0.648028</td>\n",
       "      <td>-1.216384</td>\n",
       "      <td>0.169621</td>\n",
       "      <td>0.184851</td>\n",
       "      <td>-0.614986</td>\n",
       "      <td>-0.057883</td>\n",
       "      <td>-0.281811</td>\n",
       "      <td>-1.043617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.341222</td>\n",
       "      <td>1.853771</td>\n",
       "      <td>1.954515</td>\n",
       "      <td>-2.432568</td>\n",
       "      <td>1.321296</td>\n",
       "      <td>0.657125</td>\n",
       "      <td>1.234296</td>\n",
       "      <td>2.484890</td>\n",
       "      <td>0.958206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           f0        f1        f2        f3        f4        f5        f6  \\\n",
       "846 -0.506020  0.539483  2.124813 -1.410443  0.281646  0.704983 -0.335682   \n",
       "171  0.329096  0.767773 -1.346558 -0.523517 -0.736579 -0.215310  0.372510   \n",
       "676 -1.928833  0.560735  0.429243 -0.218027 -0.717902 -1.198535  0.377480   \n",
       "87  -0.270411  0.683119 -0.728913 -1.577573  1.075379  0.160923  1.301512   \n",
       "985 -0.070410 -0.938034  2.322082  0.648380  1.450591  0.602001 -0.556225   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "213 -1.599135 -0.207075 -1.797146  1.931475 -1.897968 -2.112377 -0.115809   \n",
       "550 -0.543467 -0.275262  0.357560 -1.152918  0.760330  0.073643  1.157647   \n",
       "955 -0.487456  0.484879 -0.287665  2.342864  1.591488 -0.922678 -0.420875   \n",
       "965 -1.107943  0.648028 -1.216384  0.169621  0.184851 -0.614986 -0.057883   \n",
       "395  0.341222  1.853771  1.954515 -2.432568  1.321296  0.657125  1.234296   \n",
       "\n",
       "           f7  clusters  \n",
       "846  0.207109  0.958206  \n",
       "171  0.200423 -1.043617  \n",
       "676 -0.870036 -1.043617  \n",
       "87   1.654272  0.958206  \n",
       "985  0.160330  0.958206  \n",
       "..        ...       ...  \n",
       "213 -2.296550 -1.043617  \n",
       "550  0.966308  0.958206  \n",
       "955  0.101707 -1.043617  \n",
       "965 -0.281811 -1.043617  \n",
       "395  2.484890  0.958206  \n",
       "\n",
       "[750 rows x 9 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to divide the df by cluster, we need to ensure we use the correct class labels, we'll use pandas to do that\n",
    "train_clusters = X_train_scaled.copy()\n",
    "test_clusters = X_test_scaled.copy()\n",
    "train_clusters['y'] = y_train\n",
    "test_clusters['y'] = y_test\n",
    "# locate the \"0\" cluster\n",
    "train_0 = train_clusters.loc[train_clusters.clusters < 0] # after scaling, 0 went negtive\n",
    "test_0 = test_clusters.loc[test_clusters.clusters < 0]\n",
    "y_train_0 = train_0.y.values\n",
    "y_test_0 = test_0.y.values\n",
    "# locate the \"1\" cluster\n",
    "train_1 = train_clusters.loc[train_clusters.clusters > 0] # after scaling, 1 dropped slightly\n",
    "test_1 = test_clusters.loc[test_clusters.clusters > 0]\n",
    "y_train_1 = train_1.y.values\n",
    "y_test_1 = test_1.y.values\n",
    "# the base dataset has no \"clusters\" feature\n",
    "X_train_base = X_train_scaled.drop(columns=['clusters'])\n",
    "X_test_base = X_test_scaled.drop(columns=['clusters'])\n",
    "# drop the targets from the training set\n",
    "X_train_0 = train_0.drop(columns=['y'])\n",
    "X_test_0 = test_0.drop(columns=['y'])\n",
    "X_train_1 = train_1.drop(columns=['y'])\n",
    "X_test_1 = test_1.drop(columns=['y'])\n",
    "datasets = {\n",
    "    'base': (X_train_base, y_train, X_test_base, y_test),\n",
    "    'cluster-feature': (X_train_scaled, y_train, X_test_scaled, y_test),\n",
    "    'cluster-0': (X_train_0, y_train_0, X_test_0, y_test_0),\n",
    "    'cluster-1': (X_train_1, y_train_1, X_test_1, y_test_1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base': (           f0        f1        f2        f3        f4        f5        f6  \\\n",
       "  846 -0.506020  0.539483  2.124813 -1.410443  0.281646  0.704983 -0.335682   \n",
       "  171  0.329096  0.767773 -1.346558 -0.523517 -0.736579 -0.215310  0.372510   \n",
       "  676 -1.928833  0.560735  0.429243 -0.218027 -0.717902 -1.198535  0.377480   \n",
       "  87  -0.270411  0.683119 -0.728913 -1.577573  1.075379  0.160923  1.301512   \n",
       "  985 -0.070410 -0.938034  2.322082  0.648380  1.450591  0.602001 -0.556225   \n",
       "  ..        ...       ...       ...       ...       ...       ...       ...   \n",
       "  213 -1.599135 -0.207075 -1.797146  1.931475 -1.897968 -2.112377 -0.115809   \n",
       "  550 -0.543467 -0.275262  0.357560 -1.152918  0.760330  0.073643  1.157647   \n",
       "  955 -0.487456  0.484879 -0.287665  2.342864  1.591488 -0.922678 -0.420875   \n",
       "  965 -1.107943  0.648028 -1.216384  0.169621  0.184851 -0.614986 -0.057883   \n",
       "  395  0.341222  1.853771  1.954515 -2.432568  1.321296  0.657125  1.234296   \n",
       "  \n",
       "             f7  \n",
       "  846  0.207109  \n",
       "  171  0.200423  \n",
       "  676 -0.870036  \n",
       "  87   1.654272  \n",
       "  985  0.160330  \n",
       "  ..        ...  \n",
       "  213 -2.296550  \n",
       "  550  0.966308  \n",
       "  955  0.101707  \n",
       "  965 -0.281811  \n",
       "  395  2.484890  \n",
       "  \n",
       "  [750 rows x 8 columns],\n",
       "  array([3, 3, 2, 1, 0, 2, 2, 2, 0, 3, 0, 0, 3, 2, 0, 0, 2, 0, 2, 2, 1, 0,\n",
       "         3, 1, 3, 2, 3, 3, 2, 1, 3, 2, 0, 3, 1, 1, 0, 2, 3, 3, 3, 0, 1, 3,\n",
       "         0, 0, 3, 0, 1, 2, 3, 2, 1, 2, 2, 3, 2, 0, 3, 2, 1, 0, 3, 0, 2, 1,\n",
       "         2, 2, 1, 3, 2, 2, 0, 0, 1, 2, 3, 1, 0, 2, 2, 1, 2, 2, 2, 1, 2, 2,\n",
       "         0, 0, 0, 3, 3, 3, 3, 2, 2, 3, 2, 0, 1, 3, 2, 0, 2, 0, 3, 3, 1, 2,\n",
       "         2, 0, 1, 0, 1, 2, 2, 1, 1, 0, 3, 0, 2, 1, 1, 3, 0, 0, 2, 3, 1, 1,\n",
       "         1, 2, 2, 3, 3, 1, 3, 1, 3, 3, 3, 2, 2, 3, 3, 1, 0, 1, 0, 1, 1, 1,\n",
       "         2, 1, 1, 2, 1, 1, 0, 2, 3, 2, 2, 0, 1, 3, 2, 1, 0, 3, 2, 0, 2, 2,\n",
       "         3, 0, 3, 3, 1, 1, 2, 0, 0, 3, 1, 0, 1, 2, 2, 1, 0, 1, 2, 2, 0, 3,\n",
       "         0, 3, 3, 0, 2, 2, 3, 0, 3, 1, 3, 3, 0, 1, 1, 3, 2, 0, 3, 0, 2, 3,\n",
       "         1, 0, 2, 3, 2, 3, 1, 1, 1, 1, 3, 1, 0, 3, 1, 1, 0, 0, 3, 0, 1, 1,\n",
       "         3, 2, 1, 0, 3, 1, 2, 2, 2, 2, 3, 2, 2, 3, 1, 0, 1, 1, 2, 3, 0, 3,\n",
       "         3, 1, 2, 3, 2, 0, 0, 1, 0, 0, 0, 1, 0, 2, 2, 2, 3, 2, 0, 0, 2, 0,\n",
       "         0, 1, 0, 3, 1, 2, 1, 0, 3, 2, 2, 0, 0, 3, 3, 3, 1, 1, 1, 1, 1, 3,\n",
       "         2, 3, 1, 2, 2, 1, 0, 0, 3, 1, 2, 0, 3, 2, 1, 1, 2, 3, 0, 1, 1, 1,\n",
       "         2, 0, 3, 1, 1, 2, 3, 3, 3, 3, 1, 2, 2, 2, 2, 1, 3, 2, 3, 1, 0, 1,\n",
       "         2, 3, 3, 3, 3, 3, 3, 1, 2, 2, 2, 0, 2, 1, 0, 0, 0, 3, 0, 3, 2, 0,\n",
       "         3, 3, 2, 0, 1, 2, 0, 0, 1, 0, 2, 1, 2, 1, 3, 2, 0, 3, 0, 0, 3, 0,\n",
       "         1, 3, 2, 0, 3, 0, 3, 3, 2, 1, 3, 3, 1, 3, 0, 0, 1, 0, 1, 2, 3, 0,\n",
       "         2, 1, 2, 0, 2, 2, 2, 0, 1, 0, 1, 3, 2, 2, 3, 0, 3, 3, 1, 0, 0, 0,\n",
       "         2, 2, 1, 1, 1, 2, 0, 3, 0, 0, 1, 3, 1, 3, 0, 1, 0, 0, 2, 2, 2, 1,\n",
       "         2, 2, 1, 0, 0, 2, 3, 3, 2, 0, 0, 3, 1, 1, 1, 3, 2, 0, 1, 1, 0, 2,\n",
       "         1, 0, 1, 1, 1, 1, 3, 1, 1, 0, 0, 0, 0, 3, 2, 3, 3, 3, 2, 0, 3, 2,\n",
       "         0, 2, 1, 3, 2, 1, 1, 2, 2, 3, 2, 3, 3, 2, 2, 0, 1, 1, 0, 0, 2, 0,\n",
       "         0, 3, 1, 3, 0, 2, 0, 1, 1, 2, 1, 2, 0, 1, 2, 2, 2, 3, 3, 3, 1, 3,\n",
       "         3, 3, 3, 2, 0, 1, 3, 2, 0, 3, 2, 3, 2, 1, 1, 2, 1, 2, 1, 0, 2, 1,\n",
       "         2, 0, 1, 2, 3, 0, 2, 1, 3, 3, 1, 3, 1, 1, 1, 3, 3, 1, 3, 2, 0, 0,\n",
       "         1, 1, 2, 0, 3, 3, 2, 1, 1, 2, 1, 2, 1, 0, 0, 1, 3, 1, 1, 2, 0, 1,\n",
       "         2, 2, 2, 1, 3, 0, 1, 3, 1, 2, 0, 0, 1, 0, 3, 2, 3, 0, 2, 1, 2, 1,\n",
       "         0, 3, 3, 0, 0, 0, 0, 1, 2, 3, 1, 0, 2, 2, 1, 3, 1, 3, 1, 2, 2, 0,\n",
       "         1, 1, 1, 0, 2, 1, 2, 2, 2, 3, 3, 1, 0, 2, 2, 0, 0, 1, 0, 0, 3, 0,\n",
       "         1, 3, 2, 0, 2, 1, 0, 3, 1, 1, 0, 1, 3, 0, 3, 2, 0, 1, 0, 2, 0, 1,\n",
       "         3, 2, 0, 3, 1, 3, 1, 1, 2, 0, 1, 1, 0, 3, 2, 3, 0, 2, 1, 2, 0, 2,\n",
       "         2, 3, 1, 1, 2, 0, 1, 2, 3, 2, 2, 3, 0, 3, 3, 3, 0, 0, 0, 1, 2, 0,\n",
       "         0, 2]),\n",
       "             f0        f1        f2        f3        f4        f5        f6  \\\n",
       "  214  0.105185 -0.722836  1.191385 -0.041498  0.846694  0.653088 -0.261638   \n",
       "  459 -0.487039  0.386842 -0.045375 -1.127654  0.491769  0.471694 -0.002141   \n",
       "  230  0.656676  0.941085 -1.818413  0.879602  0.801242 -0.552017  0.521559   \n",
       "  479  0.591968 -0.595231  0.370229  0.171663  0.857644  0.834567 -0.516708   \n",
       "  597 -1.357688  0.532304 -0.463863 -0.407481 -0.740229 -0.820166  0.286073   \n",
       "  ..        ...       ...       ...       ...       ...       ...       ...   \n",
       "  698  0.329655  1.163243  1.242117  0.060196 -1.043116 -0.031706 -0.882982   \n",
       "  27   0.488590 -0.894309  0.651512  0.627357  0.226698  0.505982 -0.629396   \n",
       "  650 -0.977994  0.360396 -0.224333 -1.916425  0.415516 -0.396040  1.960120   \n",
       "  432  0.898802  0.174556 -0.824115 -0.274911 -0.635342  0.457377 -0.336942   \n",
       "  199  0.610357 -0.475556 -1.251789 -0.259876 -0.275727 -0.122566  0.988481   \n",
       "  \n",
       "             f7  \n",
       "  214  0.236927  \n",
       "  459  0.405976  \n",
       "  230  1.035696  \n",
       "  479  0.308406  \n",
       "  597 -0.649533  \n",
       "  ..        ...  \n",
       "  698 -0.636961  \n",
       "  27  -0.322829  \n",
       "  650  1.299632  \n",
       "  432 -0.046871  \n",
       "  199  0.543321  \n",
       "  \n",
       "  [250 rows x 8 columns],\n",
       "  array([3, 2, 1, 0, 0, 0, 3, 3, 0, 0, 1, 3, 3, 1, 3, 3, 3, 2, 1, 1, 0, 2,\n",
       "         1, 3, 1, 0, 3, 3, 2, 3, 1, 0, 1, 2, 3, 2, 3, 1, 1, 1, 3, 0, 2, 1,\n",
       "         3, 1, 1, 1, 0, 0, 3, 1, 1, 2, 2, 0, 3, 1, 3, 0, 0, 0, 0, 2, 3, 2,\n",
       "         1, 3, 1, 3, 1, 2, 2, 0, 3, 2, 0, 0, 3, 0, 0, 3, 0, 0, 3, 0, 3, 0,\n",
       "         0, 1, 0, 3, 3, 0, 3, 0, 1, 2, 2, 2, 2, 3, 1, 0, 0, 1, 0, 1, 3, 0,\n",
       "         1, 3, 1, 0, 3, 2, 0, 0, 1, 0, 3, 2, 0, 3, 2, 0, 1, 2, 1, 2, 0, 3,\n",
       "         2, 3, 2, 2, 0, 3, 2, 0, 3, 0, 0, 1, 1, 3, 2, 1, 2, 1, 3, 1, 3, 2,\n",
       "         1, 3, 1, 3, 2, 2, 1, 0, 2, 3, 0, 1, 1, 1, 0, 0, 0, 3, 0, 0, 0, 2,\n",
       "         0, 3, 3, 0, 2, 0, 3, 0, 0, 3, 0, 0, 3, 1, 1, 3, 2, 0, 2, 1, 1, 2,\n",
       "         0, 2, 1, 3, 2, 0, 3, 3, 0, 2, 3, 2, 2, 2, 1, 1, 0, 2, 1, 1, 3, 3,\n",
       "         1, 0, 2, 0, 3, 2, 3, 3, 3, 3, 0, 1, 3, 3, 2, 2, 1, 3, 1, 0, 2, 0,\n",
       "         3, 1, 2, 3, 0, 2, 1, 3])),\n",
       " 'cluster-feature': (           f0        f1        f2        f3        f4        f5        f6  \\\n",
       "  846 -0.506020  0.539483  2.124813 -1.410443  0.281646  0.704983 -0.335682   \n",
       "  171  0.329096  0.767773 -1.346558 -0.523517 -0.736579 -0.215310  0.372510   \n",
       "  676 -1.928833  0.560735  0.429243 -0.218027 -0.717902 -1.198535  0.377480   \n",
       "  87  -0.270411  0.683119 -0.728913 -1.577573  1.075379  0.160923  1.301512   \n",
       "  985 -0.070410 -0.938034  2.322082  0.648380  1.450591  0.602001 -0.556225   \n",
       "  ..        ...       ...       ...       ...       ...       ...       ...   \n",
       "  213 -1.599135 -0.207075 -1.797146  1.931475 -1.897968 -2.112377 -0.115809   \n",
       "  550 -0.543467 -0.275262  0.357560 -1.152918  0.760330  0.073643  1.157647   \n",
       "  955 -0.487456  0.484879 -0.287665  2.342864  1.591488 -0.922678 -0.420875   \n",
       "  965 -1.107943  0.648028 -1.216384  0.169621  0.184851 -0.614986 -0.057883   \n",
       "  395  0.341222  1.853771  1.954515 -2.432568  1.321296  0.657125  1.234296   \n",
       "  \n",
       "             f7  clusters  \n",
       "  846  0.207109  0.958206  \n",
       "  171  0.200423 -1.043617  \n",
       "  676 -0.870036 -1.043617  \n",
       "  87   1.654272  0.958206  \n",
       "  985  0.160330  0.958206  \n",
       "  ..        ...       ...  \n",
       "  213 -2.296550 -1.043617  \n",
       "  550  0.966308  0.958206  \n",
       "  955  0.101707 -1.043617  \n",
       "  965 -0.281811 -1.043617  \n",
       "  395  2.484890  0.958206  \n",
       "  \n",
       "  [750 rows x 9 columns],\n",
       "  array([3, 3, 2, 1, 0, 2, 2, 2, 0, 3, 0, 0, 3, 2, 0, 0, 2, 0, 2, 2, 1, 0,\n",
       "         3, 1, 3, 2, 3, 3, 2, 1, 3, 2, 0, 3, 1, 1, 0, 2, 3, 3, 3, 0, 1, 3,\n",
       "         0, 0, 3, 0, 1, 2, 3, 2, 1, 2, 2, 3, 2, 0, 3, 2, 1, 0, 3, 0, 2, 1,\n",
       "         2, 2, 1, 3, 2, 2, 0, 0, 1, 2, 3, 1, 0, 2, 2, 1, 2, 2, 2, 1, 2, 2,\n",
       "         0, 0, 0, 3, 3, 3, 3, 2, 2, 3, 2, 0, 1, 3, 2, 0, 2, 0, 3, 3, 1, 2,\n",
       "         2, 0, 1, 0, 1, 2, 2, 1, 1, 0, 3, 0, 2, 1, 1, 3, 0, 0, 2, 3, 1, 1,\n",
       "         1, 2, 2, 3, 3, 1, 3, 1, 3, 3, 3, 2, 2, 3, 3, 1, 0, 1, 0, 1, 1, 1,\n",
       "         2, 1, 1, 2, 1, 1, 0, 2, 3, 2, 2, 0, 1, 3, 2, 1, 0, 3, 2, 0, 2, 2,\n",
       "         3, 0, 3, 3, 1, 1, 2, 0, 0, 3, 1, 0, 1, 2, 2, 1, 0, 1, 2, 2, 0, 3,\n",
       "         0, 3, 3, 0, 2, 2, 3, 0, 3, 1, 3, 3, 0, 1, 1, 3, 2, 0, 3, 0, 2, 3,\n",
       "         1, 0, 2, 3, 2, 3, 1, 1, 1, 1, 3, 1, 0, 3, 1, 1, 0, 0, 3, 0, 1, 1,\n",
       "         3, 2, 1, 0, 3, 1, 2, 2, 2, 2, 3, 2, 2, 3, 1, 0, 1, 1, 2, 3, 0, 3,\n",
       "         3, 1, 2, 3, 2, 0, 0, 1, 0, 0, 0, 1, 0, 2, 2, 2, 3, 2, 0, 0, 2, 0,\n",
       "         0, 1, 0, 3, 1, 2, 1, 0, 3, 2, 2, 0, 0, 3, 3, 3, 1, 1, 1, 1, 1, 3,\n",
       "         2, 3, 1, 2, 2, 1, 0, 0, 3, 1, 2, 0, 3, 2, 1, 1, 2, 3, 0, 1, 1, 1,\n",
       "         2, 0, 3, 1, 1, 2, 3, 3, 3, 3, 1, 2, 2, 2, 2, 1, 3, 2, 3, 1, 0, 1,\n",
       "         2, 3, 3, 3, 3, 3, 3, 1, 2, 2, 2, 0, 2, 1, 0, 0, 0, 3, 0, 3, 2, 0,\n",
       "         3, 3, 2, 0, 1, 2, 0, 0, 1, 0, 2, 1, 2, 1, 3, 2, 0, 3, 0, 0, 3, 0,\n",
       "         1, 3, 2, 0, 3, 0, 3, 3, 2, 1, 3, 3, 1, 3, 0, 0, 1, 0, 1, 2, 3, 0,\n",
       "         2, 1, 2, 0, 2, 2, 2, 0, 1, 0, 1, 3, 2, 2, 3, 0, 3, 3, 1, 0, 0, 0,\n",
       "         2, 2, 1, 1, 1, 2, 0, 3, 0, 0, 1, 3, 1, 3, 0, 1, 0, 0, 2, 2, 2, 1,\n",
       "         2, 2, 1, 0, 0, 2, 3, 3, 2, 0, 0, 3, 1, 1, 1, 3, 2, 0, 1, 1, 0, 2,\n",
       "         1, 0, 1, 1, 1, 1, 3, 1, 1, 0, 0, 0, 0, 3, 2, 3, 3, 3, 2, 0, 3, 2,\n",
       "         0, 2, 1, 3, 2, 1, 1, 2, 2, 3, 2, 3, 3, 2, 2, 0, 1, 1, 0, 0, 2, 0,\n",
       "         0, 3, 1, 3, 0, 2, 0, 1, 1, 2, 1, 2, 0, 1, 2, 2, 2, 3, 3, 3, 1, 3,\n",
       "         3, 3, 3, 2, 0, 1, 3, 2, 0, 3, 2, 3, 2, 1, 1, 2, 1, 2, 1, 0, 2, 1,\n",
       "         2, 0, 1, 2, 3, 0, 2, 1, 3, 3, 1, 3, 1, 1, 1, 3, 3, 1, 3, 2, 0, 0,\n",
       "         1, 1, 2, 0, 3, 3, 2, 1, 1, 2, 1, 2, 1, 0, 0, 1, 3, 1, 1, 2, 0, 1,\n",
       "         2, 2, 2, 1, 3, 0, 1, 3, 1, 2, 0, 0, 1, 0, 3, 2, 3, 0, 2, 1, 2, 1,\n",
       "         0, 3, 3, 0, 0, 0, 0, 1, 2, 3, 1, 0, 2, 2, 1, 3, 1, 3, 1, 2, 2, 0,\n",
       "         1, 1, 1, 0, 2, 1, 2, 2, 2, 3, 3, 1, 0, 2, 2, 0, 0, 1, 0, 0, 3, 0,\n",
       "         1, 3, 2, 0, 2, 1, 0, 3, 1, 1, 0, 1, 3, 0, 3, 2, 0, 1, 0, 2, 0, 1,\n",
       "         3, 2, 0, 3, 1, 3, 1, 1, 2, 0, 1, 1, 0, 3, 2, 3, 0, 2, 1, 2, 0, 2,\n",
       "         2, 3, 1, 1, 2, 0, 1, 2, 3, 2, 2, 3, 0, 3, 3, 3, 0, 0, 0, 1, 2, 0,\n",
       "         0, 2]),\n",
       "             f0        f1        f2        f3        f4        f5        f6  \\\n",
       "  214  0.105185 -0.722836  1.191385 -0.041498  0.846694  0.653088 -0.261638   \n",
       "  459 -0.487039  0.386842 -0.045375 -1.127654  0.491769  0.471694 -0.002141   \n",
       "  230  0.656676  0.941085 -1.818413  0.879602  0.801242 -0.552017  0.521559   \n",
       "  479  0.591968 -0.595231  0.370229  0.171663  0.857644  0.834567 -0.516708   \n",
       "  597 -1.357688  0.532304 -0.463863 -0.407481 -0.740229 -0.820166  0.286073   \n",
       "  ..        ...       ...       ...       ...       ...       ...       ...   \n",
       "  698  0.329655  1.163243  1.242117  0.060196 -1.043116 -0.031706 -0.882982   \n",
       "  27   0.488590 -0.894309  0.651512  0.627357  0.226698  0.505982 -0.629396   \n",
       "  650 -0.977994  0.360396 -0.224333 -1.916425  0.415516 -0.396040  1.960120   \n",
       "  432  0.898802  0.174556 -0.824115 -0.274911 -0.635342  0.457377 -0.336942   \n",
       "  199  0.610357 -0.475556 -1.251789 -0.259876 -0.275727 -0.122566  0.988481   \n",
       "  \n",
       "             f7  clusters  \n",
       "  214  0.236927  0.958206  \n",
       "  459  0.405976  0.958206  \n",
       "  230  1.035696  0.958206  \n",
       "  479  0.308406  0.958206  \n",
       "  597 -0.649533 -1.043617  \n",
       "  ..        ...       ...  \n",
       "  698 -0.636961 -1.043617  \n",
       "  27  -0.322829  0.958206  \n",
       "  650  1.299632  0.958206  \n",
       "  432 -0.046871  0.958206  \n",
       "  199  0.543321  0.958206  \n",
       "  \n",
       "  [250 rows x 9 columns],\n",
       "  array([3, 2, 1, 0, 0, 0, 3, 3, 0, 0, 1, 3, 3, 1, 3, 3, 3, 2, 1, 1, 0, 2,\n",
       "         1, 3, 1, 0, 3, 3, 2, 3, 1, 0, 1, 2, 3, 2, 3, 1, 1, 1, 3, 0, 2, 1,\n",
       "         3, 1, 1, 1, 0, 0, 3, 1, 1, 2, 2, 0, 3, 1, 3, 0, 0, 0, 0, 2, 3, 2,\n",
       "         1, 3, 1, 3, 1, 2, 2, 0, 3, 2, 0, 0, 3, 0, 0, 3, 0, 0, 3, 0, 3, 0,\n",
       "         0, 1, 0, 3, 3, 0, 3, 0, 1, 2, 2, 2, 2, 3, 1, 0, 0, 1, 0, 1, 3, 0,\n",
       "         1, 3, 1, 0, 3, 2, 0, 0, 1, 0, 3, 2, 0, 3, 2, 0, 1, 2, 1, 2, 0, 3,\n",
       "         2, 3, 2, 2, 0, 3, 2, 0, 3, 0, 0, 1, 1, 3, 2, 1, 2, 1, 3, 1, 3, 2,\n",
       "         1, 3, 1, 3, 2, 2, 1, 0, 2, 3, 0, 1, 1, 1, 0, 0, 0, 3, 0, 0, 0, 2,\n",
       "         0, 3, 3, 0, 2, 0, 3, 0, 0, 3, 0, 0, 3, 1, 1, 3, 2, 0, 2, 1, 1, 2,\n",
       "         0, 2, 1, 3, 2, 0, 3, 3, 0, 2, 3, 2, 2, 2, 1, 1, 0, 2, 1, 1, 3, 3,\n",
       "         1, 0, 2, 0, 3, 2, 3, 3, 3, 3, 0, 1, 3, 3, 2, 2, 1, 3, 1, 0, 2, 0,\n",
       "         3, 1, 2, 3, 0, 2, 1, 3])),\n",
       " 'cluster-0': (           f0        f1        f2        f3        f4        f5        f6  \\\n",
       "  171  0.329096  0.767773 -1.346558 -0.523517 -0.736579 -0.215310  0.372510   \n",
       "  676 -1.928833  0.560735  0.429243 -0.218027 -0.717902 -1.198535  0.377480   \n",
       "  578 -0.227465 -2.587559  0.020521  1.342083  0.087607 -0.150550  0.101844   \n",
       "  643 -1.085344 -0.771835 -1.073039 -0.054152 -1.351718 -1.151334  1.041911   \n",
       "  308 -1.453408 -1.515447 -0.625609  0.896745 -0.739744 -0.605149 -0.446102   \n",
       "  ..        ...       ...       ...       ...       ...       ...       ...   \n",
       "  277 -0.633715 -0.483045 -1.610146 -0.568715 -1.097493  0.469979 -1.043434   \n",
       "  152  0.025616 -2.442791 -2.172339  1.152145  0.795528 -0.004976  0.497715   \n",
       "  213 -1.599135 -0.207075 -1.797146  1.931475 -1.897968 -2.112377 -0.115809   \n",
       "  955 -0.487456  0.484879 -0.287665  2.342864  1.591488 -0.922678 -0.420875   \n",
       "  965 -1.107943  0.648028 -1.216384  0.169621  0.184851 -0.614986 -0.057883   \n",
       "  \n",
       "             f7  clusters  \n",
       "  171  0.200423 -1.043617  \n",
       "  676 -0.870036 -1.043617  \n",
       "  578 -0.897328 -1.043617  \n",
       "  643 -0.888352 -1.043617  \n",
       "  308 -1.822825 -1.043617  \n",
       "  ..        ...       ...  \n",
       "  277 -1.415987 -1.043617  \n",
       "  152 -0.109405 -1.043617  \n",
       "  213 -2.296550 -1.043617  \n",
       "  955  0.101707 -1.043617  \n",
       "  965 -0.281811 -1.043617  \n",
       "  \n",
       "  [359 rows x 9 columns],\n",
       "  array([3, 2, 2, 2, 2, 0, 3, 0, 2, 0, 2, 2, 3, 3, 3, 2, 0, 3, 1, 1, 3, 0,\n",
       "         1, 2, 3, 2, 2, 0, 3, 2, 0, 2, 3, 2, 2, 0, 2, 3, 1, 2, 2, 1, 2, 2,\n",
       "         2, 2, 0, 3, 3, 2, 2, 2, 0, 1, 0, 2, 0, 3, 2, 2, 0, 3, 2, 1, 1, 1,\n",
       "         2, 2, 3, 1, 3, 2, 2, 3, 0, 1, 2, 1, 1, 2, 3, 2, 2, 1, 2, 2, 2, 2,\n",
       "         0, 3, 3, 2, 1, 0, 2, 1, 0, 1, 2, 0, 3, 2, 0, 1, 0, 3, 2, 3, 2, 2,\n",
       "         3, 1, 1, 0, 1, 2, 1, 1, 2, 2, 0, 1, 3, 3, 1, 3, 2, 0, 0, 0, 0, 1,\n",
       "         2, 2, 0, 1, 2, 2, 0, 3, 1, 3, 2, 3, 1, 2, 2, 1, 0, 1, 2, 2, 1, 0,\n",
       "         1, 1, 2, 0, 3, 3, 3, 3, 2, 2, 2, 1, 2, 3, 1, 2, 3, 1, 2, 0, 3, 0,\n",
       "         3, 3, 2, 0, 2, 1, 2, 2, 1, 3, 2, 3, 0, 3, 2, 0, 3, 3, 2, 3, 3, 1,\n",
       "         1, 2, 0, 1, 2, 2, 1, 0, 3, 2, 3, 0, 3, 0, 2, 2, 2, 0, 1, 2, 2, 1,\n",
       "         2, 0, 0, 3, 2, 0, 3, 3, 2, 1, 2, 1, 3, 0, 0, 3, 2, 3, 2, 3, 2, 2,\n",
       "         3, 1, 1, 2, 3, 1, 1, 0, 2, 1, 3, 1, 1, 2, 2, 0, 1, 2, 2, 3, 3, 3,\n",
       "         2, 0, 1, 3, 2, 1, 2, 1, 0, 2, 2, 1, 3, 1, 1, 1, 3, 3, 3, 2, 0, 1,\n",
       "         2, 1, 1, 1, 2, 1, 0, 3, 1, 2, 2, 2, 1, 1, 2, 0, 3, 0, 1, 0, 3, 1,\n",
       "         3, 1, 1, 3, 1, 3, 1, 2, 0, 1, 0, 1, 2, 2, 2, 3, 2, 2, 3, 1, 3, 2,\n",
       "         0, 2, 0, 1, 3, 2, 2, 2, 0, 3, 1, 2, 0, 3, 2, 3, 2, 2, 1, 2, 3, 2,\n",
       "         3, 3, 3, 0, 1, 0, 0]),\n",
       "             f0        f1        f2        f3        f4        f5        f6  \\\n",
       "  597 -1.357688  0.532304 -0.463863 -0.407481 -0.740229 -0.820166  0.286073   \n",
       "  959 -0.268639  1.357405 -0.779883  1.123039 -0.318902 -2.005474  1.455746   \n",
       "  854  0.527464  0.476875 -1.731448  0.488991 -0.727132 -0.813553  0.725747   \n",
       "  379 -1.827805 -2.566820 -0.332169  0.807528 -0.789184  0.166471 -1.503709   \n",
       "  349 -1.394529 -0.167365  1.034857 -0.056057  0.509694  0.144588 -0.821733   \n",
       "  ..        ...       ...       ...       ...       ...       ...       ...   \n",
       "  513 -0.392617  0.183025  0.551160  0.407552 -0.254597 -0.741623  0.429526   \n",
       "  174 -0.387095 -1.609003  0.163188  0.958298  0.082476 -0.385173  0.306362   \n",
       "  917 -0.887432  0.378437  0.777901 -0.167653 -1.393676 -1.410339  1.166948   \n",
       "  606  0.135656  1.117060  1.918552 -0.128658 -0.230946 -0.769186  0.926793   \n",
       "  698  0.329655  1.163243  1.242117  0.060196 -1.043116 -0.031706 -0.882982   \n",
       "  \n",
       "             f7  clusters  \n",
       "  597 -0.649533 -1.043617  \n",
       "  959  0.511602 -1.043617  \n",
       "  854  0.181357 -1.043617  \n",
       "  379 -2.771865 -1.043617  \n",
       "  349 -0.746166 -1.043617  \n",
       "  ..        ...       ...  \n",
       "  513 -0.143316 -1.043617  \n",
       "  174 -0.552071 -1.043617  \n",
       "  917 -0.468223 -1.043617  \n",
       "  606  0.682776 -1.043617  \n",
       "  698 -0.636961 -1.043617  \n",
       "  \n",
       "  [109 rows x 9 columns],\n",
       "  array([0, 0, 3, 0, 0, 3, 2, 2, 3, 3, 1, 1, 3, 1, 1, 2, 1, 3, 0, 0, 0, 2,\n",
       "         2, 1, 2, 0, 0, 3, 0, 3, 0, 3, 3, 3, 0, 1, 3, 0, 1, 3, 1, 0, 0, 0,\n",
       "         1, 2, 2, 2, 1, 2, 0, 2, 2, 3, 2, 0, 0, 1, 2, 1, 3, 2, 1, 2, 2, 2,\n",
       "         3, 1, 1, 3, 0, 0, 2, 0, 3, 0, 2, 3, 3, 3, 1, 2, 0, 1, 2, 0, 2, 1,\n",
       "         3, 2, 0, 3, 2, 2, 2, 1, 0, 2, 1, 3, 0, 2, 3, 3, 3, 2, 2, 3, 3])),\n",
       " 'cluster-1': (           f0        f1        f2        f3        f4        f5        f6  \\\n",
       "  846 -0.506020  0.539483  2.124813 -1.410443  0.281646  0.704983 -0.335682   \n",
       "  87  -0.270411  0.683119 -0.728913 -1.577573  1.075379  0.160923  1.301512   \n",
       "  985 -0.070410 -0.938034  2.322082  0.648380  1.450591  0.602001 -0.556225   \n",
       "  50  -0.141788 -1.261081 -0.299703  0.841298  0.962387  0.580770 -0.850867   \n",
       "  472  0.569670  0.309290 -0.596144 -0.478809  1.014557  1.360837 -1.192687   \n",
       "  ..        ...       ...       ...       ...       ...       ...       ...   \n",
       "  191  0.441477  0.197728 -0.969035  1.253689  0.609154  0.496187 -1.601774   \n",
       "  812 -0.248370 -0.455077  0.327032  0.674268  1.030057  0.272286 -0.569635   \n",
       "  762  1.858165 -0.315750  0.716735  0.186675 -0.795382  0.807800 -0.597113   \n",
       "  550 -0.543467 -0.275262  0.357560 -1.152918  0.760330  0.073643  1.157647   \n",
       "  395  0.341222  1.853771  1.954515 -2.432568  1.321296  0.657125  1.234296   \n",
       "  \n",
       "             f7  clusters  \n",
       "  846  0.207109  0.958206  \n",
       "  87   1.654272  0.958206  \n",
       "  985  0.160330  0.958206  \n",
       "  50  -0.415767  0.958206  \n",
       "  472  0.403611  0.958206  \n",
       "  ..        ...       ...  \n",
       "  191 -0.488317  0.958206  \n",
       "  812 -0.055036  0.958206  \n",
       "  762 -0.072768  0.958206  \n",
       "  550  0.966308  0.958206  \n",
       "  395  2.484890  0.958206  \n",
       "  \n",
       "  [391 rows x 9 columns],\n",
       "  array([3, 1, 0, 0, 3, 2, 0, 0, 1, 0, 3, 1, 2, 3, 2, 1, 1, 0, 2, 3, 3, 3,\n",
       "         0, 0, 3, 0, 2, 1, 2, 3, 1, 3, 0, 1, 2, 2, 1, 0, 1, 0, 1, 2, 0, 0,\n",
       "         3, 3, 3, 3, 2, 3, 1, 0, 1, 1, 2, 2, 1, 1, 0, 0, 1, 3, 0, 0, 2, 3,\n",
       "         1, 3, 1, 3, 3, 3, 3, 1, 1, 0, 1, 1, 1, 2, 1, 0, 0, 3, 1, 0, 3, 0,\n",
       "         3, 1, 1, 0, 0, 3, 1, 2, 2, 3, 0, 3, 0, 2, 3, 3, 3, 3, 1, 1, 3, 2,\n",
       "         0, 0, 1, 0, 3, 1, 1, 1, 3, 1, 0, 3, 1, 0, 3, 0, 1, 3, 0, 3, 2, 2,\n",
       "         3, 2, 2, 3, 1, 1, 2, 3, 0, 2, 1, 0, 0, 2, 2, 3, 0, 2, 0, 0, 1, 0,\n",
       "         3, 1, 0, 3, 2, 0, 3, 3, 1, 1, 1, 1, 0, 3, 0, 3, 1, 2, 3, 1, 1, 1,\n",
       "         2, 3, 1, 2, 3, 0, 1, 3, 3, 3, 3, 3, 2, 2, 0, 2, 1, 0, 0, 0, 3, 2,\n",
       "         1, 0, 0, 0, 1, 0, 3, 0, 0, 1, 0, 3, 1, 3, 1, 0, 0, 0, 3, 2, 0, 2,\n",
       "         2, 0, 1, 2, 3, 1, 0, 0, 1, 1, 1, 0, 3, 0, 1, 3, 3, 0, 1, 0, 0, 2,\n",
       "         2, 1, 2, 3, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 3, 3,\n",
       "         0, 0, 1, 2, 2, 2, 3, 3, 2, 2, 0, 0, 0, 0, 3, 0, 2, 0, 1, 2, 3, 3,\n",
       "         1, 3, 3, 2, 0, 3, 3, 2, 1, 2, 1, 1, 0, 1, 2, 3, 0, 2, 3, 3, 1, 1,\n",
       "         0, 1, 0, 3, 3, 2, 2, 0, 1, 1, 0, 1, 2, 3, 0, 3, 1, 0, 1, 0, 3, 2,\n",
       "         2, 1, 2, 3, 0, 0, 0, 0, 2, 0, 2, 2, 2, 1, 1, 2, 3, 1, 0, 0, 0, 1,\n",
       "         0, 0, 0, 1, 3, 1, 0, 1, 3, 0, 0, 1, 0, 0, 1, 3, 1, 3, 1, 1, 1, 0,\n",
       "         0, 2, 1, 2, 0, 2, 3, 1, 1, 0, 2, 3, 0, 0, 0, 2, 2]),\n",
       "             f0        f1        f2        f3        f4        f5        f6  \\\n",
       "  214  0.105185 -0.722836  1.191385 -0.041498  0.846694  0.653088 -0.261638   \n",
       "  459 -0.487039  0.386842 -0.045375 -1.127654  0.491769  0.471694 -0.002141   \n",
       "  230  0.656676  0.941085 -1.818413  0.879602  0.801242 -0.552017  0.521559   \n",
       "  479  0.591968 -0.595231  0.370229  0.171663  0.857644  0.834567 -0.516708   \n",
       "  241  1.322665  0.845992 -1.227889 -0.213856  1.334956  2.156869 -2.453554   \n",
       "  ..        ...       ...       ...       ...       ...       ...       ...   \n",
       "  181 -0.277923  0.689982  1.645207 -0.701414  0.589931  0.508397 -0.442175   \n",
       "  27   0.488590 -0.894309  0.651512  0.627357  0.226698  0.505982 -0.629396   \n",
       "  650 -0.977994  0.360396 -0.224333 -1.916425  0.415516 -0.396040  1.960120   \n",
       "  432  0.898802  0.174556 -0.824115 -0.274911 -0.635342  0.457377 -0.336942   \n",
       "  199  0.610357 -0.475556 -1.251789 -0.259876 -0.275727 -0.122566  0.988481   \n",
       "  \n",
       "             f7  clusters  \n",
       "  214  0.236927  0.958206  \n",
       "  459  0.405976  0.958206  \n",
       "  230  1.035696  0.958206  \n",
       "  479  0.308406  0.958206  \n",
       "  241  0.347633  0.958206  \n",
       "  ..        ...       ...  \n",
       "  181  0.311116  0.958206  \n",
       "  27  -0.322829  0.958206  \n",
       "  650  1.299632  0.958206  \n",
       "  432 -0.046871  0.958206  \n",
       "  199  0.543321  0.958206  \n",
       "  \n",
       "  [141 rows x 9 columns],\n",
       "  array([3, 2, 1, 0, 3, 1, 3, 3, 1, 3, 3, 1, 1, 0, 2, 1, 3, 1, 0, 3, 3, 1,\n",
       "         0, 1, 2, 2, 3, 1, 1, 3, 0, 2, 1, 1, 0, 0, 3, 1, 2, 0, 3, 0, 3, 1,\n",
       "         3, 1, 3, 2, 0, 3, 2, 0, 0, 0, 0, 0, 1, 0, 3, 3, 0, 2, 2, 2, 2, 3,\n",
       "         1, 0, 0, 1, 0, 1, 3, 2, 0, 3, 0, 3, 0, 1, 3, 3, 2, 0, 0, 3, 1, 1,\n",
       "         3, 2, 3, 1, 1, 3, 3, 1, 0, 0, 1, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 1,\n",
       "         3, 2, 1, 3, 0, 3, 2, 1, 1, 3, 1, 2, 0, 3, 3, 3, 0, 1, 3, 1, 3, 1,\n",
       "         0, 2, 0, 1, 2, 0, 2, 1, 3]))}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.49      0.48        70\n",
      "           1       0.25      0.12      0.16        58\n",
      "           2       0.44      0.62      0.52        52\n",
      "           3       0.61      0.69      0.64        70\n",
      "\n",
      "    accuracy                           0.48       250\n",
      "   macro avg       0.45      0.48      0.45       250\n",
      "weighted avg       0.45      0.48      0.46       250\n",
      "\n",
      "cluster-feature\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.50      0.50        70\n",
      "           1       0.33      0.14      0.20        58\n",
      "           2       0.46      0.67      0.55        52\n",
      "           3       0.63      0.71      0.67        70\n",
      "\n",
      "    accuracy                           0.51       250\n",
      "   macro avg       0.48      0.51      0.48       250\n",
      "weighted avg       0.49      0.51      0.49       250\n",
      "\n",
      "cluster-0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.79      0.70        28\n",
      "           1       0.74      0.67      0.70        21\n",
      "           2       0.92      0.74      0.82        31\n",
      "           3       0.67      0.69      0.68        29\n",
      "\n",
      "    accuracy                           0.72       109\n",
      "   macro avg       0.74      0.72      0.72       109\n",
      "weighted avg       0.74      0.72      0.73       109\n",
      "\n",
      "cluster-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.64      0.66        42\n",
      "           1       0.64      0.49      0.55        37\n",
      "           2       0.47      0.81      0.60        21\n",
      "           3       0.73      0.66      0.69        41\n",
      "\n",
      "    accuracy                           0.63       141\n",
      "   macro avg       0.63      0.65      0.63       141\n",
      "weighted avg       0.65      0.63      0.63       141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "def run_exps(datasets: dict) -> pd.DataFrame:\n",
    "    '''\n",
    "    runs experiments on a dict of datasets\n",
    "    '''\n",
    "    # initialize a logistic regression classifier\n",
    "    model = LogisticRegression(class_weight='balanced', solver='lbfgs', random_state=999, max_iter=250)\n",
    "    \n",
    "    dfs = []\n",
    "    results = []\n",
    "    conditions = []\n",
    "    scoring = ['accuracy','precision_weighted','recall_weighted','f1_weighted']\n",
    "    for condition, splits in datasets.items():\n",
    "        X_train = splits[0]\n",
    "        y_train = splits[1]\n",
    "        X_test = splits[2]\n",
    "        y_test = splits[3]\n",
    "        \n",
    "        kfold = model_selection.KFold(n_splits=5, shuffle=True, random_state=90210)\n",
    "        cv_results = model_selection.cross_validate(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "        clf = model.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(condition)\n",
    "        print(classification_report(y_test, y_pred))\n",
    "    results.append(cv_results)\n",
    "    conditions.append(condition)\n",
    "    this_df = pd.DataFrame(cv_results)\n",
    "    this_df['condition'] = condition\n",
    "    dfs.append(this_df)\n",
    "    final = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    # We have wide format data, lets use pd.melt to fix this\n",
    "    results_long = pd.melt(final,id_vars=['condition'],var_name='metrics', value_name='values')\n",
    "    \n",
    "    # fit time metrics, we don't need these\n",
    "    time_metrics = ['fit_time','score_time'] \n",
    "    results = results_long[~results_long['metrics'].isin(time_metrics)] # get df without fit data\n",
    "    results = results.sort_values(by='values')\n",
    "    \n",
    "    return results\n",
    "df = run_exps(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
